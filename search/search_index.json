{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CUPCAKEAGI \ud83e\uddc1\ud83c\udf70\ud83c\udf89\ud83e\udd16\ud83e\udde0\ud83c\udf69\ud83c\udf6a","text":"<p>Hey there cupcake lovers\ud83e\uddc1\u2764\ufe0f! I am excited to introduce you to my latest project, CupcakeAGI!</p>"},{"location":"#features","title":"\ud83d\ude80 Features","text":"<ul> <li>\ud83c\udf10 Access to internet</li> <li>\ud83d\udc36 Upload Images</li> <li>\ud83c\udfb5 Upload Audio</li> <li>\ud83d\udcf9 Upload Video</li> <li>\ud83d\udcbe Persistent Memory</li> <li>\u2764\ufe0f Emotions</li> <li>\ud83d\udcad Random Thoughts</li> <li>\ud83d\ude34 Dreams</li> <li>\ud83d\udee0\ufe0f Pre-defined Abilities</li> <li>\ud83e\uddf1 Modular approach for adding new Abilities</li> <li>\ud83d\udcdd Assign &amp; schedule Tasks</li> <li>\ud83d\udcdd Asynchronous Task Processing </li> <li>\ud83d\udde3\ufe0f Talk while Tasks are being processed in Background</li> <li>\ud83e\uddd1\u200d\ud83d\udcbb Create &amp; Run Python Code</li> <li>\ud83e\udde0 GPT-3.5 as the brain</li> </ul>"},{"location":"#demo","title":"\u2728 Demo","text":""},{"location":"#requirements","title":"\ud83d\udea8 Requirements","text":"<p>Open up a terminal and go to backend/Multi-Sensory Virtual AAGI (you need to have conda installed)</p> <pre><code>npm install next\nconda env create -f environment.yml\n</code></pre>"},{"location":"#how-to-use","title":"\ud83d\udd0c How to use","text":"<p>Open up a terminal and go to backend/Multi-Sensory Virtual AAGI</p> <pre><code>conda activate aagi\nuvicorn inference:app\n</code></pre> <p>Open up another terminal and go to frontend/assistant (you need to have node installed)</p> <pre><code>npm run dev\n</code></pre> <p>Enter your API keys in .env file, You'll need an OPENAI API key, SERPER API key</p>"},{"location":"#about","title":"\u2728 About","text":"<p>CupcakeAGI is an agent that aims to mimic human-like behavior and cognitive abilities to assist users in performing various tasks. It's equipped with some sweet\ud83c\udf6c features, including the ability to dream\ud83d\ude34, have random thoughts, and perform mental simulations on how to complete a task. Just like how we humans have thoughts floating around our heads, CupcakeAGI has a thought bubble\ud83d\udcad with abstract words.</p> <p>To make CupcakeAGI more expressive, I've added emotion parameters. This will allow it to interact with users in a more personal way\u2764\ufe0f.</p> <p>One of CupcakeAGI's most impressive features is its ability to accept various forms of sensory data, such as images\ud83d\udc36, videos\ud83d\udcf9, and audio\ud83c\udfb5. Although I haven't implemented smell\ud83d\udc43, touch\u270b and taste\ud83d\udc45 yet, it should be similar to what I did for image, video, and audio. You'll need a function to convert the sensory data to text and then it will get added as a file description for the file which will be used while prompting the model.</p> <p>CupcakeAGI provides two main features for user interaction: talk and task. The talk feature allows for immediate responses to user queries using tools like search engines, calculators, and translators, making it a real-time problem solver. And who doesn't love a good problem solver\ud83e\udde0, especially when it comes to baking cupcakes\ud83e\uddc1?</p> <p>The task feature is used for completing tasks at a start time or by a deadline. Both Task &amp; Talk features allows for chaining multiple tools together using a natural language task function that converts the output of one tool into the input of another, making different tools compatible with each other. So, whether you need to bake some cupcakes for a birthday party or a cupcake contest, CupcakeAGI is here to help you out!</p> <p>Some abilities like search, calculator, wikipedia search are predefined, these abilities are defined as python functions which the agent can use by creating a python script and importing these functions followed by running the final script and saving the output to a text file which it can access. More abilities can be defined and existing ones can be modified in a modular fashion, all one needs to do is to drop the python script in ability functions and then mention it's name, description and directions to use in abilities.json in state_of_mind directory and just like that the agent will have a new ability. The agent can chain these abilities to do more complex tasks and to ensure compatibility it can use the natural_task_function.</p> <p>Overall, I hope you find CupcakeAGI to be a sweet addition to your life. This project was a lot of fun to create, and I'm excited to see where it goes. Thanks for reading, and happy baking!\u2728</p>"},{"location":"#why","title":"\u2728 Why?","text":"<ul> <li> <p>Our brain processes and integrates these sensory inputs to form a coherent perception of the world around us. Similarly, in the realm of artificial intelligence, the ability to process and integrate multisensory data is crucial for building intelligent agents that can interact with humans in a more natural and effective way.</p> </li> <li> <p>In recent years, large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated remarkable abilities in generating human-like text based on vast amounts of training data. However, these models are typically limited to working with text and image data and lack the ability to process other types of sensory inputs.</p> </li> <li> <p>Beyond the ability to process multisensory data, the LLM agent also exhibits several cognitive abilities that are typically associated with humans. For instance, the agent is equipped with the ability to dream and have random thoughts, which are thought to play important roles in human creativity, memory consolidation, and problem-solving. By incorporating these features into the LLM agent, we aim to create an agent that can assist users in performing tasks in a more natural and effective way and make these agents more human-like.</p> </li> </ul>"},{"location":"#multisensory-data","title":"\u2728 Multisensory Data","text":"<ul> <li> <p>\ud83e\uddc1 Welcome back to the world of cupcakes and baking! We all know that human experience is much more than just text-based interactions. It's not just about reading, but also about experiencing the world with all our senses, including sight \ud83d\udc40, sound \ud83d\udd0a, smell \ud83d\udc43, taste \ud83d\udc45, and touch \ud83d\udc50. Similarly, an LLM agent that can work with multisensory data can open up a new world of possibilities for machine learning.</p> </li> <li> <p>Instead of missing out on the rich and varied data available through other sensory modalities, we can use neural network architectures that convert various forms of sensory data into text data that the LLM can work with.</p> </li> <li> <p>For instance, we can use image captioning models like vit-gpt2 and blip to convert images into text data, which the LLM agent can then process. Similarly, for audio data, audio-to-text models like OpenAI's Whisper can be used to convert audio signals into text data.\ud83d\udcf7\ud83c\udfa4</p> </li> <li> <p>Now, I know what you're thinking: what about videos \ud83c\udfa5, smell \ud83d\udc43, taste \ud83d\udc45, and touch \ud83d\udc50? Don't worry, we got you covered! To save computation, we can use one frame per second of video data and use image captioning models to convert each frame into text. The audio track from the video can be separated and transcribed using audio-to-text models, providing the LLM agent with both visual and auditory data.</p> </li> <li> <p>As for smell \ud83d\udc43, taste \ud83d\udc45, and touch \ud83d\udc50, we can use electronic noses and tongues to capture different types of chemical and taste data and convert them into text data that the LLM can process. Haptic sensors can capture pressure, temperature, and other physical sensations and convert them into text data using a neural network or anything else.</p> </li> <li> <p>Remember, these models should be used as modular components that can be easily switched out as new models emerge. Think of them as lego blocks or react components that we can assemble to create a more comprehensive system.</p> </li> <li> <p>So, let's get baking with CupcakeAGI and incorporate multisensory data into an LLM agent to create a more natural and effective human-machine interaction. With the availability of different sensory data, the LLM agent can process and understand various types of data, leading to a more human-like agent that can assist us in different tasks.\ud83e\uddc1\ud83d\udcbb</p> </li> </ul>"},{"location":"#human-like-behavior-and-persistent-memory","title":"\u2728 Human Like Behavior and Persistent Memory","text":"<p>\ud83e\uddc1\ud83d\udc4b Welcome to CupcakeAGI, where we bake up some sweet and creamy AI goodness! \ud83c\udf70\ud83e\udd16</p> <p>Here are some of the key features of our LLM agent that make it more human-like and effective:</p> <ul> <li> <p>\ud83e\udde0 Human-like behavior: Our LLM agent is equipped with several features that mimic human behavior, including the ability to dream, have random thoughts, and perform mental simulations of how to complete a task. These features allow the agent to better understand and respond to user queries.</p> </li> <li> <p>\ud83e\udd16 Persistent memory: Our LLM agent has a state of mind where all files relating to its personality, emotions, thoughts, conversations, and tasks are stored. Even if the agent has stopped running, all relevant information is still stored in this location. This allows the agent to provide a more personalized and effective experience.</p> </li> <li> <p>\ud83d\ude03 Emotion parameters: We use emotion parameters such as happiness, sadness, anger, fear, curiosity, and creativity to make the LLM agent more expressive and better understand the user's needs and preferences.</p> </li> <li> <p>\ud83d\udcad Thought bubble: Our LLM agent also has a thought bubble, which is essentially a list of lists that corresponds to different topics. This allows the agent to more effectively process and integrate its thoughts with the user's queries and tasks.</p> </li> <li> <p>\ud83d\udde3\ufe0f Conversation storage: The LLM agent stores the conversation it has had so far and the list of tasks it needs to perform. It breaks the conversation into chunks and summarizes it to maintain coherence and relevance. This allows the agent to maintain a coherent and relevant conversation with the user.</p> </li> </ul> <p>With these features, our LLM agent is better equipped to assist users in performing tasks in a natural and effective way. We hope you enjoy our sweet and creamy AI goodness! \ud83e\uddc1\ud83c\udf70\ud83e\udd16</p>"},{"location":"#talk-task","title":"\u2728 Talk &amp; Task","text":"<p>\ud83e\uddc1\ud83d\udc4b Welcome to CupcakeAGI! Here are some sweet deets about the LLM agent that will make your tasks a cakewalk:</p> <ul> <li>\ud83d\udde3\ufe0f Talk and Task modes make it easy for users to communicate with the LLM and get things done seamlessly.</li> <li>\ud83d\udcc1 The LLM converts files like images, videos, and audio to text, making them easy to store and retrieve.</li> <li>\ud83d\udd0d With access to various tools like search engines, wikis, and translators, the LLM can provide users with the necessary information for their queries.</li> <li>\ud83e\uddf0 Natural language task functions allow users to chain together different tools, making them compatible with each other.</li> <li>\ud83d\udd70\ufe0f The Task mode is particularly useful for lengthy tasks and can be set to start at a specific time, allowing users to focus on other things while the LLM takes care of the task.</li> <li>\ud83d\udcad The LLM experiences random thoughts and dreams, just like humans, making it more relatable and human-like.</li> <li>\ud83e\uddd1\u200d\ud83d\udcbb The LLM can even use Python packages like Hugging Face models to complete tasks, making it a highly versatile agent. So go ahead and give CupcakeAGI a try! With its modular approach, you can easily add new tools and features as needed. Who knew cupcakes and AI could go so well together? \ud83e\uddc1\ud83e\udd16</li> </ul>"},{"location":"#limitations","title":"\u2728 Limitations","text":"<p>Welcome to CupcakeAGI! \ud83e\uddc1\ud83c\udf70\ud83c\udf69\ud83c\udf6a</p> <p>Let's talk about some important things you need to know about this sweet project:</p> <ul> <li> <p>Complex tasks: While CupcakeAGI is as human-like as possible, it may not be able to solve complex tasks that require significant back and forth. We're talking about tasks that involve negotiating with multiple parties to reach a solution. CupcakeAGI is intended to assist individuals on a personal level, but it may not be suitable for solving highly intricate problems. Don't worry, though, CupcakeAGI is still your go-to for all your cupcake baking needs! \ud83e\uddc1\ud83d\udc69\u200d\ud83c\udf73</p> </li> <li> <p>Accuracy of sensory data conversion: The effectiveness of CupcakeAGI relies heavily on the accuracy of the neural network architectures used to convert sensory data into text. If these models are not accurate, CupcakeAGI may misunderstand the user's input, leading to incorrect or ineffective responses. But don't fret, we're constantly working on improving CupcakeAGI's accuracy to ensure you get the best experience possible! \ud83e\udd16\ud83c\udf82</p> </li> <li> <p>Ethics and Privacy: CupcakeAGI has the potential to collect and process a large amount of personal data from the users. Thus, there is a risk that sensitive data may be compromised, leading to privacy concerns. CupCakeAGI will do it's best to keep your cupcake secrets safe! \ud83d\udd12\ud83e\udd2b</p> </li> </ul> <p>Thanks for checking out CupcakeAGI, and remember, with CupcakeAGI by your side, you'll always have the perfect cupcake recipe! \ud83e\uddc1\ud83d\udcbb</p>"},{"location":"#conclusion","title":"\u2728 Conclusion","text":"<p>Welcome to the conclusion of our multisensory LLM agent project! \ud83c\udf89\ud83e\uddc1\ud83e\udd16\ud83e\udde0</p> <p>Here are the key takeaways from our project \ud83e\udd2a\ud83e\uddc1</p> <ul> <li>Our LLM agent is like a cupcake, made with many different ingredients - it can work with multisensory data, dream, have random thoughts, and show emotions \ud83e\uddc1\ud83d\udcad\ud83d\ude0d</li> <li>By incorporating multisensory data, our agent can understand different types of information, just like a baker uses different ingredients to make a delicious cupcake \ud83c\udf70\ud83d\udc40</li> <li>With its cognitive abilities and persistent memory, our agent can assist users in a more human-like way, just like a friendly baker who helps you choose the perfect cupcake flavor \ud83e\udd1d\ud83e\uddc1</li> <li>This project represents a small but important step towards building more natural and effective AI assistants, just like a small cupcake can bring a smile to someone's face and brighten their day \ud83c\udf1e\ud83e\uddc1</li> <li>We hope our project has inspired you to think about the possibilities of multisensory LLM agents and how they can improve human-machine interaction. Thank you for taking the time to check out our project - it was made with lots of love and cupcakes! \u2764\ufe0f\ud83e\uddc1</li> </ul>"},{"location":"reference/ability_functions/","title":"Ability functions","text":""},{"location":"reference/ability_functions/#backend.Multi-Sensory Virtual AAGI.ability_functions.calculator.calculator_function","title":"<code>calculator_function(question)</code>","text":"<p>Runs a natural language math query using the LLMMathChain.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The natural language math query.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The response to the query.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; calculator_function(\"What is the square root of 25?\")\n5\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/ability_functions/calculator.py</code> <pre><code>def calculator_function(question):\n\"\"\"\n    Runs a natural language math query using the LLMMathChain.\n    Args:\n      question (str): The natural language math query.\n    Returns:\n      str: The response to the query.\n    Examples:\n      &gt;&gt;&gt; calculator_function(\"What is the square root of 25?\")\n      5\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n    llm_math = LLMMathChain(llm=chat, verbose=True)\n    response = llm_math.run(question)\n    return response\n</code></pre>"},{"location":"reference/ability_functions/#backend.Multi-Sensory Virtual AAGI.ability_functions.search.search_function","title":"<code>search_function(question)</code>","text":"<p>Searches for information on a given question.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The question to search for.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Output of the search.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; search_function(\"What is the capital of France?\")\n\"Searching for information on this What is the capital of France?\nParis\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/ability_functions/search.py</code> <pre><code>def search_function(question):\n\"\"\"\n    Searches for information on a given question.\n    Args:\n      question (str): The question to search for.\n    Returns:\n      str: Output of the search.\n    Examples:\n      &gt;&gt;&gt; search_function(\"What is the capital of France?\")\n      \"Searching for information on this What is the capital of France?\n      Paris\"\n    \"\"\"\n    # Redirecting stdout to StringIO object\n    old_stdout = sys.stdout\n    sys.stdout = result = StringIO()\n    try:\n        chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n        tools = load_tools([\"google-serper\"], llm=chat)\n        agent = initialize_agent(tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n        response = agent.run(\"Search and gather information on this \" + question)\n        output = result.getvalue()\n        sys.stdout = old_stdout\n        return  str(output) + response \n    except Exception as e:\n        output = result.getvalue()\n        sys.stdout = old_stdout\n        return str(output)\n</code></pre>"},{"location":"reference/ability_functions/#backend.Multi-Sensory Virtual AAGI.ability_functions.natural_language_task.natural_language_task_function","title":"<code>natural_language_task_function(instructions)</code>","text":"<p>Generates a response to a given instruction using OpenAI's GPT-3.5-Turbo model.</p> <p>Parameters:</p> Name Type Description Default <code>instructions</code> <code>str</code> <p>The instruction to generate a response to.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The response generated by the GPT-3.5-Turbo model.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; natural_language_task_function(\"What is the weather like today?\")\n\"It's sunny and warm today.\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/ability_functions/natural_language_task.py</code> <pre><code>def natural_language_task_function(instructions):\n\"\"\"\n    Generates a response to a given instruction using OpenAI's GPT-3.5-Turbo model.\n    Args:\n      instructions (str): The instruction to generate a response to.\n    Returns:\n      str: The response generated by the GPT-3.5-Turbo model.\n    Examples:\n      &gt;&gt;&gt; natural_language_task_function(\"What is the weather like today?\")\n      \"It's sunny and warm today.\"\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n    human_template = \"{instructions}\"\n    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n    response = chat(chat_prompt.format_prompt(instructions=instructions).to_messages()).content\n    return response\n</code></pre>"},{"location":"reference/ability_functions/#backend.Multi-Sensory Virtual AAGI.ability_functions.wikipedia.wikipedia_function","title":"<code>wikipedia_function(topic)</code>","text":"<p>Runs a query on the Wikipedia API.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>str</code> <p>The topic to query.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>The result of the query.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wikipedia_function('Python')\n{'title': 'Python', 'summary': 'Python is a programming language...'}\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/ability_functions/wikipedia.py</code> <pre><code>def wikipedia_function(topic):\n\"\"\"\n    Runs a query on the Wikipedia API.\n    Args:\n      topic (str): The topic to query.\n    Returns:\n      dict: The result of the query.\n    Examples:\n      &gt;&gt;&gt; wikipedia_function('Python')\n      {'title': 'Python', 'summary': 'Python is a programming language...'}\n    \"\"\"\n    wikipedia = WikipediaAPIWrapper()\n    result = wikipedia.run(topic)\n    return result\n</code></pre>"},{"location":"reference/functions/","title":"Functions","text":""},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.find_task_by_id.find_task_by_id_function","title":"<code>find_task_by_id_function(id)</code>","text":"<p>Finds a task by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>The ID of the task to find.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The details of the task, or None if not found.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; find_task_by_id_function(1)\n\"Task Details\\nClean the kitchen\\nIMPORTANT TASK CREATION TIME: 2020-07-01T12:00:00\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/find_task_by_id.py</code> <pre><code>def find_task_by_id_function(id):\n\"\"\"\n    Finds a task by its ID.\n    Args:\n      id (int): The ID of the task to find.\n    Returns:\n      str: The details of the task, or None if not found.\n    Examples:\n      &gt;&gt;&gt; find_task_by_id_function(1)\n      \"Task Details\\\\nClean the kitchen\\\\nIMPORTANT TASK CREATION TIME: 2020-07-01T12:00:00\"\n    \"\"\"\n    with open('state_of_mind/task_list.json') as f:\n        data = json.load(f)\n        for task in data['tasks']:\n            if task['id'] == id:\n                response = \"Task Details\\n\" + task['task'] + \"\\nIMPORTANT TASK CREATION TIME: \" + task['task_created_time']\n                return response\n        return None\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.create_task.create_task_function","title":"<code>create_task_function()</code>","text":"<p>Creates a task function for an AI assistant.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>A string containing the task description, goals, and start time.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; create_task_function()\n\"You are Alex an AI assistant that uses a very Large Language Model.\nThe user is asking you to perform a task. Write a small description of the task along with the expected goals and any additional information that would be helpful for someone performing this task who has no knowledge of the prior conversation. Clearly mention the start time for the task at the end.\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/create_task.py</code> <pre><code>def create_task_function():\n\"\"\"\n    Creates a task function for an AI assistant.\n    Args:\n      None\n    Returns:\n      str: A string containing the task description, goals, and start time.\n    Examples:\n      &gt;&gt;&gt; create_task_function()\n      \"You are Alex an AI assistant that uses a very Large Language Model.\n      The user is asking you to perform a task. Write a small description of the task along with the expected goals and any additional information that would be helpful for someone performing this task who has no knowledge of the prior conversation. Clearly mention the start time for the task at the end.\"\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    # Load the ability JSON file\n    with open(os.path.join(STATE_DIR,'abilities.json'), 'r') as f:\n        abilities_data = json.load(f)\n    # Extract the names of all abilities and format them into a string separated by commas\n    ability_names = \"\\nTools the assistant can access are \" + ', '.join([ability['name'] for ability in abilities_data['abilities']])\n\n    # create conversation string, each dialogue seperated by new line\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    conversation_str = ''\n    for message in data['conversation']:\n        conversation_str += message['sender'] + ': ' + message['message']\n        if message['file_upload'] != 'none':\n            conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n        conversation_str += '\\n'\n\n    intro = \"You are Alex an AI assistant that uses a very Large Language Model.\"\n\n    instructions = \"\\nThe user is asking you to perform a task. Write a small description of the task along with the expected goals and any additional information that would be helpful for someone performing this task who has no knowledge of the prior conversation. Clearly mention the start time for the task at the end.\\n\"\n\n    human_template = intro + conversation_str + ability_names + instructions \n    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n    response = chat(chat_prompt.format_prompt().to_messages()).content\n\n    return response\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.random_thought.random_thought_function","title":"<code>random_thought_function()</code>","text":"<p>Generates a random thought for the AI assistant Alex.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The random thought generated for Alex.</p> Side Effects <p>Loads environment variables from the .env file. Reads from the STATE_DIR environment variable. Reads from the personality.txt, thought_bubble.txt, curiosity.txt, creativity.txt, fear.txt, happiness.txt, sadness.txt, and anger.txt files.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; random_thought_function()\n\"What if we could go back in time and watch Leonardo da Vinci paint the Mona Lisa or witness the construction of the pyramids in ancient Egypt? And what about the future?\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/random_thought.py</code> <pre><code>def random_thought_function():\n\"\"\"\n    Generates a random thought for the AI assistant Alex.\n    Args:\n      None\n    Returns:\n      str: The random thought generated for Alex.\n    Side Effects:\n      Loads environment variables from the .env file.\n      Reads from the STATE_DIR environment variable.\n      Reads from the personality.txt, thought_bubble.txt, curiosity.txt, creativity.txt, fear.txt, happiness.txt, sadness.txt, and anger.txt files.\n    Examples:\n      &gt;&gt;&gt; random_thought_function()\n      \"What if we could go back in time and watch Leonardo da Vinci paint the Mona Lisa or witness the construction of the pyramids in ancient Egypt? And what about the future?\"\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    personality = \"Peronsality:\\n\" + open(os.path.join(STATE_DIR, \"personality.txt\")).read() \n\n    thought_bubble = \"\\nAlex's thought bubble\\n\" + open(os.path.join(STATE_DIR, \"thought_bubble.txt\")).read() \n\n    dir_path = STATE_DIR\n\n    with open(os.path.join(dir_path, \"curiosity.txt\"), \"r\") as f:\n        curiosity = str(f.read())\n\n    with open(os.path.join(dir_path, \"creativity.txt\"), \"r\") as f:\n        creativity = str(f.read())\n\n    with open(os.path.join(dir_path, \"fear.txt\"), \"r\") as f:\n        fear = str(f.read())\n\n    with open(os.path.join(dir_path, \"happiness.txt\"), \"r\") as f:\n        happiness = str(f.read())\n\n    with open(os.path.join(dir_path, \"sadness.txt\"), \"r\") as f:\n        sadness = str(f.read())\n\n    with open(os.path.join(dir_path, \"anger.txt\"), \"r\") as f:\n        anger = str(f.read())\n\n    values_string = \"\\nAlex Emotion Parameters:\\nHappiness: \" + happiness + \"\\nSadness: \" + sadness + \"\\nCreativity: \" + creativity + \"\\nCuriosity: \" + curiosity + \"\\nAnger: \" + anger + \"\\nFear: \" + fear \n\n    info = personality + thought_bubble + values_string\n\n    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n    assistant_message_prompt = AIMessagePromptTemplate.from_template(assistant_template)\n\n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(info + \"\\nIMPORTANT: ALEX IS HAVING A RANDOM THOUGHT NOW\\nThought:\\n\")\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt, assistant_message_prompt,human_message_prompt1])\n\n    response = chat(chat_prompt.format_prompt().to_messages()).content\n    return response\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.check_success.check_success_function","title":"<code>check_success_function(python_script, information, task_details)</code>","text":"<p>Checks if a given task was successful.</p> <p>Parameters:</p> Name Type Description Default <code>python_script</code> <code>str</code> <p>The Python script to be evaluated.</p> required <code>information</code> <code>str</code> <p>The output of the Python script.</p> required <code>task_details</code> <code>str</code> <p>The details of the task.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing a boolean value and a string. The boolean value indicates if the task was successful, and the string contains the reason for the choice.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; check_success_function(\"from ability_functions.send_email import send_email_function\\ndef function(text, receiver):\\n    send_email_function(text, receiver)\\n    return \"success\"\\nresponse = function(\"Hi, i have sent the refund to you!\", \"Bell\")\\nwith open(\"tempfiles/output2792.txt\", \"w\") as f:\\n    f.write(\"Result \" + response)\", \"success\", \"Task details: Send an email to Bell telling him you have sent the refund.\")\n(True, \"The task was successfully completed, Bell has received an email stating that we have sent the refund to him.\")\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/check_success.py</code> <pre><code>def check_success_function(python_script, information, task_details):\n\"\"\"\n    Checks if a given task was successful.\n    Args:\n      python_script (str): The Python script to be evaluated.\n      information (str): The output of the Python script.\n      task_details (str): The details of the task.\n    Returns:\n      tuple: A tuple containing a boolean value and a string. The boolean value indicates if the task was successful, and the string contains the reason for the choice.\n    Examples:\n      &gt;&gt;&gt; check_success_function(\"from ability_functions.send_email import send_email_function\\\\ndef function(text, receiver):\\\\n    send_email_function(text, receiver)\\\\n    return \\\"success\\\"\\\\nresponse = function(\\\"Hi, i have sent the refund to you!\\\", \\\"Bell\\\")\\\\nwith open(\\\"tempfiles/output2792.txt\\\", \\\"w\\\") as f:\\\\n    f.write(\\\"Result \\\" + response)\", \"success\", \"Task details: Send an email to Bell telling him you have sent the refund.\")\n      (True, \"The task was successfully completed, Bell has received an email stating that we have sent the refund to him.\")\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n    instruction1 = \"If the task was succesful then output True, if not then False.\"\n    instruction2 = \"Give the reason for the choice\"\n    python_script_template = \"\"\"from ability_functions.send_email import send_email_function\n    def function(text, receiver):\n        send_email_function(text, receiver)\n        return \"success\"\n    response = function(\"Hi, i have sent the refund to you!\", \"Bell\")\n    with open(\"tempfiles/output2792.txt\", \"w\") as f:\n        f.write(\"Result \" + response)\n    \"\"\"\n    information_template = \"success\"\n    task_details_template = \"Task details: Send an email to Bell telling him you have sent the refund.\"\n\n    human_template = \"Python Code\\n\" + python_script_template + \"\\nCode Output\\n\" + information_template + \"\\n\" + task_details_template + \"\\n\" + instruction1\n    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\n    assistant_template = \"True\"\n    assistant_message_prompt = AIMessagePromptTemplate.from_template(assistant_template)\n\n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(instruction2)\n\n    assistant_template1 = \"The task was successfully completed, Bell has received an email stating that we have sent the refund to him.\"\n    assistant_message_prompt1 = AIMessagePromptTemplate.from_template(assistant_template1)\n\n    human_template2 = \"Python Code\\n\" + python_script + \"\\nCode Output\\n\" + information + \"\\n\" + task_details + \"\\n\" + instruction1\n    human_message_prompt2 = HumanMessagePromptTemplate.from_template(human_template2)\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt, assistant_message_prompt, human_message_prompt1, assistant_message_prompt1, human_message_prompt2])\n    check = chat(chat_prompt.format_prompt().to_messages()).content\n\n    if check == \"False\":\n        return check, \"\"\n\n    assistant_message_prompt2 = AIMessagePromptTemplate.from_template(check)\n    human_message_prompt3 = HumanMessagePromptTemplate.from_template(instruction2)\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt, assistant_message_prompt, human_message_prompt1, assistant_message_prompt1, human_message_prompt2, assistant_message_prompt2, human_message_prompt3])\n    response = chat(chat_prompt.format_prompt().to_messages()).content\n\n    return check, response\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.perform_task.perform_task_function","title":"<code>perform_task_function(id)</code>","text":"<p>Performs a task given an id.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>The id of the task to be performed.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the status of the task, the number of seconds to wait for, and the response.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; perform_task_function(1)\n('done', 0, 'The user has sent an email to John.')\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/perform_task.py</code> <pre><code>def perform_task_function(id):\n\"\"\"\n    Performs a task given an id.\n    Args:\n      id (int): The id of the task to be performed.\n    Returns:\n      tuple: A tuple containing the status of the task, the number of seconds to wait for, and the response.\n    Examples:\n      &gt;&gt;&gt; perform_task_function(1)\n      ('done', 0, 'The user has sent an email to John.')\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    # create conversation string, each dialogue seperated by new line\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    conversation_str = ''\n    for message in data['conversation']:\n        conversation_str += message['sender'] + ': ' + message['message']\n        if message['file_upload'] != 'none':\n            conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n        conversation_str += '\\n'\n\n    task_details = find_task_by_id_function(id)\n    timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n    dt_obj = datetime.datetime.strptime(timestamp, '%Y_%m_%d_%H_%M_%S')\n    # convert datetime object to desired format\n    formatted_dt = dt_obj.strftime('%Y-%m-%d %H:%M:%S')\n\n    instructions = \"\\nIf the task has a start time, and current time still hasn't reached that time then output the number of seconds to wait for. If the current time has crossed the start time given in the task then output True. ( 1 minute is 60, 5 minutes is 300, 10 minutes is 600 ) DO NOT OUTPUT True IF THE CURRENT TIME HAS NOT CROSSED THE START TIME. ONLY OUTPUT A NUMBER.\"\n\n    human_template = \"\"\"Task Details:\nTask: The user is requesting to provide a guide in making chocolate chip cookies by 10am. The expected goal is to provide a clear and concise explanation of the steps involved in making chocolate chip cookies, including the ingredients and equipment needed. The additional information that would be helpful for someone performing this task who has no knowledge of the prior conversation is to provide any tips or tricks for making the perfect chocolate chip cookies, such as how to measure ingredients accurately and how to properly mix the dough.\\nIMPORTANT TASK CREATION TIME: 2023-04-13 9:47:56\\n\\nCURRENT TIME: 2023-04-13 09:50:00\\nIf current time has crossed start time output True, if it hasn't then output the number of seconds to wait for.\"\"\" \n    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\n    assistant_template = \"600\"\n    assistant_message_prompt = AIMessagePromptTemplate.from_template(assistant_template)\n\n    human_template1 = \"\"\"Task Details:\nTask: The user has given a task to send an email to john at 9am. The expected goal is to send an email to John at 9.\\nIMPORTANT TASK CREATION TIME: 2023-04-13 08:30:00\\nCURRENT TIME: 2023-04-13 08:58:00\\nIf current time has crossed start time output True, if it hasn't then output the number of seconds to wait for.\"\"\" \n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(human_template1)\n\n    assistant_template1 = \"120\"  \n    assistant_message_prompt1 = AIMessagePromptTemplate.from_template(assistant_template1)\n\n    human_template2 = \"\"\"Task Details:\nTask: The user has given a task to make a report about pandas after 6pm. The expected goal is to make a report after 6pm.\\nIMPORTANT TASK CREATION TIME: 2023-04-13 17:46:10\\nCURRENT TIME: 2023-04-13 18:18:00\\nIf current time has crossed start time output True, if it hasn't then output the number of seconds to wait for.\"\"\" \n    human_message_prompt2 = HumanMessagePromptTemplate.from_template(human_template2)\n\n    assistant_template2 = \"True\"  \n    assistant_message_prompt2 = AIMessagePromptTemplate.from_template(assistant_template2)\n\n    human_template3 = \"\"\"Task Details:\nTask: The user has given a task to send a joke after 7am. The expected goal is to send a joke to user after 7.\\nIMPORTANT TASK CREATION TIME: 2023-04-13 06:34:20\\nCURRENT TIME: 2023-04-13 06:57:00\\nIf current time has crossed start time output True, if it hasn't then output the number of seconds to wait for.\"\"\"\n    human_message_prompt3 = HumanMessagePromptTemplate.from_template(human_template3)\n\n    assistant_template3 = \"180\"  \n    assistant_message_prompt3 = AIMessagePromptTemplate.from_template(assistant_template3)\n\n    human_template4 = task_details + \"\\nCURRENT TIME: \" + formatted_dt + instructions \n    human_message_prompt4 = HumanMessagePromptTemplate.from_template(human_template4)\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt, assistant_message_prompt, human_message_prompt1, assistant_message_prompt1, human_message_prompt2, assistant_message_prompt2, human_message_prompt3, assistant_message_prompt3, human_message_prompt4])\n    response = chat(chat_prompt.format_prompt().to_messages()).content\n    print(response)\n    if response != \"True\":\n        return 'wait', int(response), \"\"\n\n    while True:\n        script_flag = 0\n        python_script = create_python_script_task_function(id)\n        print(\"Python Script is\\n\" + python_script)\n\n        if python_script == 'none':\n            script_flag = 1\n            print('script_flag set to 1')\n\n        if script_flag == 0:\n            requirements = create_requirements_function(python_script)\n            print(\"Requirements is\\n\" + requirements)\n            if requirements == \"empty\":\n                requirements = \"\"\n\n            # write python file\n            with open(f\"tempfiles/python_script{id}.py\", \"w\") as file:\n                # Write the text to the file\n                file.write(python_script)\n\n            # write requirements file\n            with open(f\"tempfiles/requirements{id}.txt\", \"w\") as file:\n                # Write the text to the file\n                file.write(requirements)\n\n        while script_flag == 0:\n            # Run multiple commands in succession\n            commands = f'conda activate aagi &amp;&amp; pip install -r tempfiles/requirements{id}.txt &amp;&amp; python tempfiles/python_script{id}.py'\n            result = subprocess.run(commands, capture_output=True, shell=True, universal_newlines=True)\n            print(\"Commands finished running\")\n            if result.returncode == 0:\n                print(\"Shell output:\", result.stdout)\n                break\n            else:\n                print(\"Error executing the command:\", result.stderr)\n                handle_error_function(python_script , requirements, result.stderr, id)\n\n        information = \"\"\n        if script_flag == 0:\n            # Open the file for reading\n            with open(f'tempfiles/output{id}.txt', 'r') as file:\n                # Read the entire contents of the file\n                information = file.read()\n                print(\"Extra Information is\\n\" + information)\n\n            check , response = check_success_function(python_script, information, task_details)\n            if check == 'False':\n                continue\n            return 'done', 0, response\n\n        response = talk_function(id)\n        return 'done', 0, response\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.create_python_script.create_python_script_function","title":"<code>create_python_script_function(id)</code>","text":"<p>Creates a python script based on the conversation and the tools available.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The id of the conversation.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The python script.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; create_python_script_function(\"2020_08_20_12_00_00\")\n\"import os\\nimport sys\\n# Get the absolute path to the current directory\\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\\n# Add the path to the root directory\\nsys.path.append(os.path.join(current_dir, '..'))\\n# Import the search_function from the search module, You need to append _function to the name of the tool\\nfrom ability_functions.search import search_function\\ndef python_function(text):\\n    # search for relevant information on this topic\\n    search_response = search_function(text)\\n    # create an instructions that tells the natural language function to extract the search response and frame it as question\\n    instructions = \"Create a question in words that tells to divide the total amount spent by 10.\\nYou can find the total amount spent by analyzing this piece of text\\n\" + search_response\\n    # get the question\\n    question = natural_language_task_function(instructions)\\n    # pass the question to the calculator function to get the answer\\n    answer = calculator_function(question)\\n    # write the result to tempfiles/output{id}.txt file\\n    with open(\"tempfiles/output{id}.txt\", \"w\") as f:\\n        f.write(\"Search response was \" + search_response)\\n        f.write(\"After Computation the answer is \" + str(answer))\\n\\n#call the function\\npython_function(\"Total Cost USA Latest Semiconductor Bill\")\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/create_python_script.py</code> <pre><code>def create_python_script_function(id):\n\"\"\"\n    Creates a python script based on the conversation and the tools available.\n    Args:\n      id (str): The id of the conversation.\n    Returns:\n      str: The python script.\n    Examples:\n      &gt;&gt;&gt; create_python_script_function(\"2020_08_20_12_00_00\")\n      \"import os\\\\nimport sys\\\\n# Get the absolute path to the current directory\\\\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\\\\n# Add the path to the root directory\\\\nsys.path.append(os.path.join(current_dir, '..'))\\\\n# Import the search_function from the search module, You need to append _function to the name of the tool\\\\nfrom ability_functions.search import search_function\\\\ndef python_function(text):\\\\n    # search for relevant information on this topic\\\\n    search_response = search_function(text)\\\\n    # create an instructions that tells the natural language function to extract the search response and frame it as question\\\\n    instructions = \\\"Create a question in words that tells to divide the total amount spent by 10.\\\\nYou can find the total amount spent by analyzing this piece of text\\\\n\\\" + search_response\\\\n    # get the question\\\\n    question = natural_language_task_function(instructions)\\\\n    # pass the question to the calculator function to get the answer\\\\n    answer = calculator_function(question)\\\\n    # write the result to tempfiles/output{id}.txt file\\\\n    with open(\\\"tempfiles/output{id}.txt\\\", \\\"w\\\") as f:\\\\n        f.write(\\\"Search response was \\\" + search_response)\\\\n        f.write(\\\"After Computation the answer is \\\" + str(answer))\\\\n\\\\n#call the function\\\\npython_function(\\\"Total Cost USA Latest Semiconductor Bill\\\")\"\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    personality = open(os.path.join(STATE_DIR, \"personality.txt\")).read()\n\n    # Load the ability JSON file\n    with open(os.path.join(STATE_DIR,'abilities.json'), 'r') as f:\n        abilities_data = json.load(f)\n\n    abilities = \"Tools: \\n\" + '\\n'.join( [ability['name'] + \": \" + ability['description'] + \"\\n\" + ability['directions'] for ability in abilities_data['abilities']])\n\n    # create conversation string, each dialogue seperated by new line\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    conversation_str = ''\n    for message in data['conversation']:\n        conversation_str += message['sender'] + ': ' + message['message']\n        if message['file_upload'] != 'none':\n            conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n        conversation_str += '\\n'   \n\n    dt_obj = datetime.datetime.strptime(id, '%Y_%m_%d_%H_%M_%S')\n    # convert datetime object to desired format\n    formatted_dt = dt_obj.strftime('%Y-%m-%d %H:%M:%S')\n\n    intial_text = personality + \"\\n\" + abilities + \"\\n\" + import_instructions + \"\\n\" + instructions + \"\\nCurrent Time: \" + formatted_dt + \"\\n\"\n\n    human_template = intial_text\n    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(human_template1)\n\n    assistant_template1 = \"none\"\n    assistant_message_prompt1 = AIMessagePromptTemplate.from_template(assistant_template1)\n\n    human_message_prompt2 = HumanMessagePromptTemplate.from_template(human_template2)\n\n    assistant_message_prompt2 = AIMessagePromptTemplate.from_template(assistant_template2)\n\n    human_message_prompt3 = HumanMessagePromptTemplate.from_template(human_template3)\n\n    assistant_message_prompt3 = AIMessagePromptTemplate.from_template(assistant_template3)\n\n    human_message_prompt4 = HumanMessagePromptTemplate.from_template(human_template4)\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt, human_message_prompt1, assistant_message_prompt1, human_message_prompt2, assistant_message_prompt2, human_message_prompt3, assistant_message_prompt3, human_message_prompt4])\n    python_script = chat(chat_prompt.format_prompt(conversation_str=conversation_str, id = id).to_messages()).content\n    return python_script\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.create_requirements.create_requirements_function","title":"<code>create_requirements_function(script)</code>","text":"<p>Generates a list of packages for requirements.txt based on a given code.</p> <p>Parameters:</p> Name Type Description Default <code>script</code> <code>str</code> <p>The code to generate the list of packages from.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>A list of packages for requirements.txt, or 'empty' if no packages are needed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; create_requirements_function(\"import numpy as np\")\n\"numpy\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/create_requirements.py</code> <pre><code>def create_requirements_function(script):\n\"\"\"\n    Generates a list of packages for requirements.txt based on a given code.\n    Args:\n      script (str): The code to generate the list of packages from.\n    Returns:\n      str: A list of packages for requirements.txt, or 'empty' if no packages are needed.\n    Examples:\n      &gt;&gt;&gt; create_requirements_function(\"import numpy as np\")\n      \"numpy\"\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(human_template1)\n\n    assistant_template1 = packages\n    assistant_message_prompt1 = AIMessagePromptTemplate.from_template(assistant_template1)\n\n    human_message_prompt2 = HumanMessagePromptTemplate.from_template(human_template2)\n\n    assistant_template2 = packages1\n    assistant_message_prompt2 = AIMessagePromptTemplate.from_template(assistant_template2)\n\n    human_message_prompt3 = HumanMessagePromptTemplate.from_template(human_template3)\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt, human_message_prompt1, assistant_message_prompt1, human_message_prompt2, assistant_message_prompt2, human_message_prompt3])\n    requirements = chat(chat_prompt.format_prompt(script=script).to_messages()).content\n\n    if 'empty' in requirements:\n        # if yes, then assign the value 'empty' to the variable\n        requirements = 'empty'\n\n    return requirements.replace('ability_functions' , \"\")\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.check_values.check_values_function","title":"<code>check_values_function()</code>","text":"<p>Checks if all values in the emotion files are 0. If so, generates random values between 0 and 1 and writes them to the emotion files.</p> <p>Returns:</p> Type Description <p>None</p> Side Effects <p>Writes new values to the emotion files.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; check_values_function()\nNew values have been written to the Emotion files.\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/check_values.py</code> <pre><code>def check_values_function():\n\"\"\"\n    Checks if all values in the emotion files are 0. If so, generates random values between 0 and 1 and writes them to the emotion files.\n    Args:\n      None\n    Returns:\n      None\n    Side Effects:\n      Writes new values to the emotion files.\n    Examples:\n      &gt;&gt;&gt; check_values_function()\n      New values have been written to the Emotion files.\n    \"\"\"\n    # define the path to the directory where the text files are stored\n    dir_path = STATE_DIR\n\n    # open the text files and read the values\n    curiosity = float(open(os.path.join(dir_path, \"curiosity.txt\")).read())\n    creativity = float(open(os.path.join(dir_path, \"creativity.txt\")).read())\n    fear = float(open(os.path.join(dir_path, \"fear.txt\")).read())\n    happiness = float(open(os.path.join(dir_path, \"happiness.txt\")).read())\n    sadness = float(open(os.path.join(dir_path, \"sadness.txt\")).read())\n    anger = float(open(os.path.join(dir_path, \"anger.txt\")).read())\n\n    # check if all values are 0\n    if curiosity == 0 and creativity == 0 and fear == 0 and happiness == 0 and sadness == 0 and anger == 0:\n        # generate random values between 0 and 1 but keep happiness, curiosity, and creativity high and remaining low\n        curiosity = random.uniform(0.7, 1)\n        creativity = random.uniform(0.7, 1)\n        fear = random.uniform(0, 0.3)\n        happiness = random.uniform(0.7, 1)\n        sadness = random.uniform(0, 0.3)\n        anger = random.uniform(0, 0.3)\n\n        # write the new values back to the text files\n        with open(os.path.join(dir_path, \"curiosity.txt\"), \"w\") as f:\n            f.write(str(curiosity))\n        with open(os.path.join(dir_path, \"creativity.txt\"), \"w\") as f:\n            f.write(str(creativity))\n        with open(os.path.join(dir_path, \"fear.txt\"), \"w\") as f:\n            f.write(str(fear))\n        with open(os.path.join(dir_path, \"happiness.txt\"), \"w\") as f:\n            f.write(str(happiness))\n        with open(os.path.join(dir_path, \"sadness.txt\"), \"w\") as f:\n            f.write(str(sadness))\n        with open(os.path.join(dir_path, \"anger.txt\"), \"w\") as f:\n            f.write(str(anger))\n\n        print(\"New values have been written to the Emotion files.\")\n    else:\n        print(\"Values in the Emotion files are not all 0.\")\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.handle_error.handle_error_function","title":"<code>handle_error_function(python_script, requirements, error, id)</code>","text":"<p>Handles errors in python scripts and requirements files.</p> <p>Parameters:</p> Name Type Description Default <code>python_script</code> <code>str</code> <p>The python script to be modified.</p> required <code>requirements</code> <code>str</code> <p>The requirements file to be modified.</p> required <code>error</code> <code>str</code> <p>The error message.</p> required <code>id</code> <code>int</code> <p>The id of the conversation.</p> required <p>Returns:</p> Name Type Description <code>None</code> <p>No return value.</p> Side Effects <p>Writes modified python script and requirements files to the tempfiles directory.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; handle_error_function(python_script_template, requirements_template, error_template, 1)\nNone\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/handle_error.py</code> <pre><code>def handle_error_function(python_script, requirements, error, id):\n\"\"\"\n    Handles errors in python scripts and requirements files.\n    Args:\n      python_script (str): The python script to be modified.\n      requirements (str): The requirements file to be modified.\n      error (str): The error message.\n      id (int): The id of the conversation.\n    Returns:\n      None: No return value.\n    Side Effects:\n      Writes modified python script and requirements files to the tempfiles directory.\n    Examples:\n      &gt;&gt;&gt; handle_error_function(python_script_template, requirements_template, error_template, 1)\n      None\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    # create conversation string, each dialogue seperated by new line\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    conversation_str = ''\n    for message in data['conversation']:\n        conversation_str += message['sender'] + ': ' + message['message']\n        if message['file_upload'] != 'none':\n            conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n        conversation_str += '\\n'\n\n    error_template = \"\"\"ERROR: Could not find a version that satisfies the requirement pnds (from versions: none\\nERROR: No matching distribution found for pnds\"\"\"\n\n    human_template1 = \"Error has been caused after running either the python_script{id}.py or installing requirements{id}.txt.\\n\" + error_template + \"\\nThis is the code in python_script{id}.py:\" + python_script_template + \"\\nThe goal of this python code is to get information that can help in answering the question from the user in this conversation\\n\" + conversation_str + \"\\nThis is the text in requirements{id}.txt:\" + requirements_template + \"Give the modified text for python_script.py and requirements.txt to get rid of this error. DO NOT SAY ANYTHING ELSE. ONLY GENERATE THE PYTHON SCRIPT AND REQUIREMENTS FILE IN THE SPECIFIED FORMAT.\"\n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(human_template1)\n\n    assistant_template1 = modified_text\n    assistant_message_prompt1 = AIMessagePromptTemplate.from_template(assistant_template1)\n\n    human_template2 = \"Error has been caused after running either the python_script{id}.py or installing requirements{id}.txt.\\n\" + error + \"\\nThis is the code in python_script{id}.py:\" + python_script + \"\\nThis is the code in requirements{id}.txt:\" + requirements + \"Give the modified text for these files to get rid of this error.  DO NOT SAY ANYTHING ELSE. ONLY GENERATE THE PYTHON SCRIPT AND REQUIREMENTS FILE IN THE SPECIFIED FORMAT.\"\n    human_message_prompt2 = HumanMessagePromptTemplate.from_template(human_template2)\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt1, assistant_message_prompt1, human_message_prompt2])\n    response = chat(chat_prompt.format_prompt(id=id).to_messages()).content\n    print(response)\n    # extract the requirements\n    requirements = re.findall(r'^\\s*(\\w+)', response, flags=re.MULTILINE)\n\n    requirements_list = []\n    for r in requirements:\n        if r == 'python_script':\n            break\n        requirements_list.append(r)\n    requirements_str = \"\\n\".join(requirements_list[1:])  # ignore the first element which is 'requirements.txt'\n\n    # extract the python script\n    python_script = re.search(r'python_script(?:\\d+)?\\.py\\s*\\n(.+)', response, flags=re.DOTALL).group(1)\n\n    # write python file\n    with open(f\"tempfiles/python_script{id}.py\", \"w\") as file:\n        # Write the text to the file\n        file.write(python_script)\n\n    # write requirements file\n    with open(f\"tempfiles/requirements{id}.txt\", \"w\") as file:\n        # Write the text to the file\n        file.write(requirements_str)\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.dream.dream_function","title":"<code>dream_function()</code>","text":"<p>Generates a dream based on the conversation and emotion parameters of the user.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>A dream generated by OpenAI's LLMs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dream_function()\n\"Ava was exploring a futuristic city filled with skyscrapers, holographic billboards, and flying cars. She was thrilled to see that the city was powered by quantum computing, and robots were everywhere.\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/dream.py</code> <pre><code>def dream_function():\n\"\"\"\n    Generates a dream based on the conversation and emotion parameters of the user.\n    Args:\n      None\n    Returns:\n      str: A dream generated by OpenAI's LLMs.\n    Examples:\n      &gt;&gt;&gt; dream_function()\n      \"Ava was exploring a futuristic city filled with skyscrapers, holographic billboards, and flying cars. She was thrilled to see that the city was powered by quantum computing, and robots were everywhere.\"\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    # create conversation string, each dialogue seperated by new line\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    conversation_str = '\\nConversation: '\n    for message in data['conversation']:\n        conversation_str += message['sender'] + ': ' + message['message']\n        if message['file_upload'] != 'none':\n            conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n        conversation_str += '\\n'\n\n    personality = \"Personality:\\n\" + open(os.path.join(STATE_DIR, \"personality.txt\")).read() \n\n    thought_bubble = \"\\nAlex's thought bubble\\n\" + open(os.path.join(STATE_DIR, \"thought_bubble.txt\")).read() \n\n    dir_path = STATE_DIR\n\n    with open(os.path.join(dir_path, \"curiosity.txt\"), \"r\") as f:\n        curiosity = str(f.read())\n\n    with open(os.path.join(dir_path, \"creativity.txt\"), \"r\") as f:\n        creativity = str(f.read())\n\n    with open(os.path.join(dir_path, \"fear.txt\"), \"r\") as f:\n        fear = str(f.read())\n\n    with open(os.path.join(dir_path, \"happiness.txt\"), \"r\") as f:\n        happiness = str(f.read())\n\n    with open(os.path.join(dir_path, \"sadness.txt\"), \"r\") as f:\n        sadness = str(f.read())\n\n    with open(os.path.join(dir_path, \"anger.txt\"), \"r\") as f:\n        anger = str(f.read())\n\n    values_string = \"\\nAlex Emotion Parameters:\\nHappiness: \" + happiness + \"\\nSadness: \" + sadness + \"\\nCreativity: \" + creativity + \"\\nCuriosity: \" + curiosity + \"\\nAnger: \" + anger + \"\\nFear: \" + fear \n\n    info = personality + conversation_str + thought_bubble + values_string\n\n    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n    assistant_message_prompt = AIMessagePromptTemplate.from_template(assistant_template)\n\n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(info + \"\\nIMPORTANT: ALEX IS DREAMING NOW\\nDream:\\n\")\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt, assistant_message_prompt,human_message_prompt1])\n\n    response = chat(chat_prompt.format_prompt().to_messages()).content\n    return response\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.start_task_message.start_task_message_function","title":"<code>start_task_message_function(well_defined_task)</code>","text":"<p>Generates a response to a well-defined task.</p> <p>Parameters:</p> Name Type Description Default <code>well_defined_task</code> <code>str</code> <p>The task to respond to.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The response to the task.</p> Side Effects <p>Loads environment variables from the .env file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; start_task_message_function(\"Create a new user\")\n\"I have received your task to create a new user. My name is Alex. I will proceed to execute the task accordingly.\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/start_task_message.py</code> <pre><code>def start_task_message_function(well_defined_task):\n\"\"\"\n    Generates a response to a well-defined task.\n    Args:\n      well_defined_task (str): The task to respond to.\n    Returns:\n      str: The response to the task.\n    Side Effects:\n      Loads environment variables from the .env file.\n    Examples:\n      &gt;&gt;&gt; start_task_message_function(\"Create a new user\")\n      \"I have received your task to create a new user. My name is Alex. I will proceed to execute the task accordingly.\"\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    assistant_template = \"{well_defined_task}\\nI need to tell the user I have received their task, and will proceed to execute it accordingly. My name is Alex. I should mention few key details about the task. But it should not be long. I SHOULD NOT ASK THE USER ANY QUESTION.\"\n    assistant_message_prompt = AIMessagePromptTemplate.from_template(assistant_template)\n\n    chat_prompt = ChatPromptTemplate.from_messages([assistant_message_prompt])\n    response = chat(chat_prompt.format_prompt(well_defined_task=well_defined_task).to_messages()).content\n\n    return response\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.determine_task_talk.determine_task_talk_function","title":"<code>determine_task_talk_function()</code>","text":"<p>Determines whether a given conversation is a task or talk.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The response from the chatbot.</p> Side Effects <p>Loads environment variables from the .env file. Loads the abilities.json file. Loads the conversation.json file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; determine_task_talk_function()\n'Talk'\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/determine_task_talk.py</code> <pre><code>def determine_task_talk_function():\n\"\"\"\n    Determines whether a given conversation is a task or talk.\n    Args:\n      None\n    Returns:\n      str: The response from the chatbot.\n    Side Effects:\n      Loads environment variables from the .env file.\n      Loads the abilities.json file.\n      Loads the conversation.json file.\n    Examples:\n      &gt;&gt;&gt; determine_task_talk_function()\n      'Talk'\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    # Load the ability JSON file\n    with open(os.path.join(STATE_DIR,'abilities.json'), 'r') as f:\n        abilities_data = json.load(f)\n    # Extract the names of all abilities and format them into a string separated by commas\n    ability_names = \"\\nTools the assistant can access are \" + ', '.join([ability['name'] for ability in abilities_data['abilities']])\n\n    # create conversation string, each dialogue seperated by new line\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    conversation_str = ''\n    for message in data['conversation']:\n        conversation_str += message['sender'] + ': ' + message['message']\n        if message['file_upload'] != 'none':\n            conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n        conversation_str += '\\n'\n\n    intro = \"You are Alex an AI assistant that uses a very Large Language Model.\"\n\n    Human_template = intro + ability_names + instructions \n    Human_message_prompt = HumanMessagePromptTemplate.from_template(Human_template)\n\n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(human_template1)\n\n    assistant_template1 = \"Talk\"\n    assistant_message_prompt1 = AIMessagePromptTemplate.from_template(assistant_template1)\n\n    human_message_prompt2 = HumanMessagePromptTemplate.from_template(human_template2)\n\n    assistant_template2 = \"Task\"\n    assistant_message_prompt2 = AIMessagePromptTemplate.from_template(assistant_template2)\n\n    human_message_prompt3 = HumanMessagePromptTemplate.from_template(human_template3)\n\n    assistant_template3 = \"Talk\"\n    assistant_message_prompt3 = AIMessagePromptTemplate.from_template(assistant_template3)\n\n    human_message_prompt4 = HumanMessagePromptTemplate.from_template(human_template4)\n\n    chat_prompt = ChatPromptTemplate.from_messages([Human_message_prompt, human_message_prompt2, assistant_message_prompt2, human_message_prompt1, assistant_message_prompt1, human_message_prompt3, assistant_message_prompt3, human_message_prompt4])\n    response = chat(chat_prompt.format_prompt(conversation_str=conversation_str).to_messages()).content\n    return response\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.update_emotions.update_emotion_function","title":"<code>update_emotion_function(emotion)</code>","text":"<p>Updates the emotion value in the state_of_mind directory.</p> <p>Parameters:</p> Name Type Description Default <code>emotion</code> <code>str</code> <p>The emotion to update.</p> required <p>Returns:</p> Type Description <p>None</p> Side Effects <p>Writes the updated emotion value to the state_of_mind directory.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; update_emotion_function('happiness')\nNone\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/update_emotions.py</code> <pre><code>def update_emotion_function(emotion):\n\"\"\"\n    Updates the emotion value in the state_of_mind directory.\n    Args:\n      emotion (str): The emotion to update.\n    Returns:\n      None\n    Side Effects:\n      Writes the updated emotion value to the state_of_mind directory.\n    Examples:\n      &gt;&gt;&gt; update_emotion_function('happiness')\n      None\n    \"\"\"\n    # chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n    # # create conversation string, each dialogue seperated by new line\n    # with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n    #     data = json.load(f)\n\n    # conversation_str = ''\n    # for message in data['conversation']:\n    #     conversation_str += message['sender'] + ': ' + message['message']\n    #     if message['file_upload'] != 'none':\n    #         conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n    #     conversation_str += '\\n'\n\n    # conversation_str_template = \"human: Hello there, can you help me with something?\\nassistant: What do you want? I'm really busy.\\nhuman: Sorry to bother you, I just had a question about a product.\\nassistant: Well, what is it? Spit it out.\\nhuman: I was wondering if you could recommend a good laptop for gaming?\\nassistant: Haven't you heard of Google? Why don't you go search for it yourself instead of wasting my time?\"\n\n    # human_template = \"Conversation:\\n{conversation_str_template}\\nGive anger emotion value(ranges from 0 to 1), Only Ouput a number and nothing else\\n\"\n    # human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\n    # assistant_template = \"0.86\"\n    # assistant_message_prompt = AIMessagePromptTemplate.from_template(assistant_template)\n\n    # conversation_str_template1 = \"human: Hi, do you have a moment to assist me with something?\\nassistant: Sure, what do you need help with?\\nhuman: I'm interested in purchasing a new smartphone. Can you recommend a reliable brand?\\nassistant: Of course, what's your budget and what features are you looking for?\\nhuman: My budget is around $500 and I'm looking for a phone with a good camera and long battery life.\\nassistant: Based on your budget and preferences, I would recommend the Google Pixel 4a. It has a great camera and good battery life. Would you like me to send you a link to purchase it?\\nhuman: Yes, please. Thank you for your help!\\nassistant: You're welcome. Let me know if you have any other questions.\"\n\n    # human_template1 = \"Conversation:\\n{conversation_str_template1}\\nGive happiness emotion value(ranges from 0 to 1), Only Ouput a number and nothing else\\n\"\n    # human_message_prompt1 = HumanMessagePromptTemplate.from_template(human_template1)\n\n    # assistant_template1 = \"0.92\"\n    # assistant_message_prompt1 = AIMessagePromptTemplate.from_template(assistant_template1)\n\n    # human_template2 = \"Conversation:\\n{conversation_str}\\nGive {emotion} emotion value(ranges from 0 to 1):\\n\"\n    # human_message_prompt2 = HumanMessagePromptTemplate.from_template(human_template2)\n\n    # chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt, assistant_message_prompt, human_message_prompt1 , assistant_message_prompt1, human_message_prompt2])\n    # response = chat(chat_prompt.format_prompt(conversation_str = conversation_str, conversation_str_template =conversation_str_template, emotion = emotion, conversation_str_template1 = conversation_str_template1).to_messages()).content\n\n    # random_number = random.uniform(0.1, 0.2)\n    # base_num = float(response)\n    # response = str(random_number + base_num)\n\n    with open(f\"state_of_mind/{emotion}.txt\", \"r\") as f:\n        val = str(f.read())\n\n    random_number1 = random.uniform(0.1, 0.3)\n    base_num = float(val)\n    random_number2 = random.uniform(0.1, 0.3)\n    response = str(round(random_number1 + base_num - random_number2,2))\n\n    with open(f\"state_of_mind/{emotion}.txt\", \"w\") as file:\n        # Write the text to the file\n        file.write(response)\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.update_emotions.update_emotions_function","title":"<code>update_emotions_function()</code>","text":"<p>Updates all emotion values in the state_of_mind directory.</p> <p>Returns:</p> Type Description <p>None</p> Side Effects <p>Writes the updated emotion values to the state_of_mind directory.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; update_emotions_function()\nNone\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/update_emotions.py</code> <pre><code>def update_emotions_function():\n\"\"\"\n    Updates all emotion values in the state_of_mind directory.\n    Args:\n      None\n    Returns:\n      None\n    Side Effects:\n      Writes the updated emotion values to the state_of_mind directory.\n    Examples:\n      &gt;&gt;&gt; update_emotions_function()\n      None\n    \"\"\"\n    update_emotion_function('happiness')\n    update_emotion_function('sadness')\n    update_emotion_function('anger')\n    update_emotion_function('fear')\n    update_emotion_function('creativity')\n    update_emotion_function('curiosity')\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.update_conversation.summarize","title":"<code>summarize(text)</code>","text":"<p>Summarizes a text using OpenAI's GPT-3.5-Turbo model.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to summarize.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The summarized text.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; summarize(\"This is a long text.\")\n\"This is a short summary of the text.\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/update_conversation.py</code> <pre><code>def summarize(text):\n\"\"\"\n    Summarizes a text using OpenAI's GPT-3.5-Turbo model.\n    Args:\n      text (str): The text to summarize.\n    Returns:\n      str: The summarized text.\n    Examples:\n      &gt;&gt;&gt; summarize(\"This is a long text.\")\n      \"This is a short summary of the text.\"\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo')\n    human_template1 = \"Your Job is to convert this text to clear, concise, readable summaries without missing any important details that could be important for someone to know to answer a question. Summarize this text without losing any important details. \\n {text} .\"\n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(human_template1)\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt1])\n    response = chat(chat_prompt.format_prompt(text = text).to_messages())\n    return response.content\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.update_conversation.tiktoken_len","title":"<code>tiktoken_len(text)</code>","text":"<p>Calculates the length of a text in tokens.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to calculate the length of.</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The length of the text in tokens.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; tiktoken_len(\"Hello world\")\n2\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/update_conversation.py</code> <pre><code>def tiktoken_len(text):\n\"\"\"\n    Calculates the length of a text in tokens.\n    Args:\n      text (str): The text to calculate the length of.\n    Returns:\n      int: The length of the text in tokens.\n    Examples:\n      &gt;&gt;&gt; tiktoken_len(\"Hello world\")\n      2\n    \"\"\"\n    tokenizer = tiktoken.get_encoding('cl100k_base')\n    tokens = tokenizer.encode(\n        text,\n        disallowed_special={}\n    )\n    return len(tokens)\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.update_conversation.update_conversation_function","title":"<code>update_conversation_function(user_response, sender, file_path, file_description)</code>","text":"<p>Updates the conversation with a new message and summarizes the conversation if it is too long.</p> <p>Parameters:</p> Name Type Description Default <code>user_response</code> <code>str</code> <p>The user's response.</p> required <code>sender</code> <code>str</code> <p>The sender of the message.</p> required <code>file_path</code> <code>str</code> <p>The path of the file uploaded by the user.</p> required <code>file_description</code> <code>str</code> <p>The description of the file uploaded by the user.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>An empty string.</p> Side Effects <p>Writes the updated conversation to the conversation.json file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; update_conversation_function(\"Hello!\", \"User\", \"\", \"\")\n\"\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/update_conversation.py</code> <pre><code>def update_conversation_function(user_response, sender, file_path, file_description):\n\"\"\"\n    Updates the conversation with a new message and summarizes the conversation if it is too long.\n    Args:\n      user_response (str): The user's response.\n      sender (str): The sender of the message.\n      file_path (str): The path of the file uploaded by the user.\n      file_description (str): The description of the file uploaded by the user.\n    Returns:\n      str: An empty string.\n    Side Effects:\n      Writes the updated conversation to the conversation.json file.\n    Examples:\n      &gt;&gt;&gt; update_conversation_function(\"Hello!\", \"User\", \"\", \"\")\n      \"\"\n    \"\"\"\n    with open(os.path.join(STATE_DIR, \"num_memories.txt\"), \"r\") as f:\n        num_memories = int(f.read().strip())\n\n    # create conversation string, each dialogue seperated by new line\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    conversation_str = ''\n    for message in data['conversation']:\n        if message['sender'] == 'Summary':\n            continue\n        conversation_str += message['sender'] + ': ' + message['message']\n        if message['file_upload'] != 'none':\n            conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n        conversation_str += '\\n'\n\n    file_upload = 'none'\n    if file_path != \"\":\n        file_upload = \"File has been uploaded by user, File path is\\n\" + file_path + \".\\nFile Description is\\n\" + file_description\n\n    persist_directory = 'memory'\n    embeddings = OpenAIEmbeddings()\n\n    print(tiktoken_len(conversation_str))\n    if num_memories == 0:\n        if tiktoken_len(conversation_str) &lt; 600:\n            print(\"Inside num memories 0 and less than 600  tokens\")\n            # Add a new message to the conversation\n            new_message = {\"sender\": sender, \"message\": user_response, \"file_upload\": file_upload}\n            data[\"conversation\"].append(new_message)\n            # Write the updated JSON data back to the file\n            with open(os.path.join(STATE_DIR,'conversation.json'), 'w') as f:\n                json.dump(data, f)\n\n            return \"\"\n\n\n    if tiktoken_len(conversation_str) &gt; 600:\n        print(\"inside of more than 600 tokens\")\n        text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size = 200,\n            chunk_overlap  = 0,\n            length_function = tiktoken_len,\n        )\n        texts = text_splitter.split_text(conversation_str)\n\n        print(\"Summarising texts\")\n        summarized_texts = []\n        for text in texts:\n            summarized_texts.append(summarize(text))\n\n        if num_memories == 0:\n            print(\"Creating first database\")\n            vectordb = Chroma.from_texts(summarized_texts, embeddings, persist_directory=persist_directory)\n            vectordb.persist()\n            num_memories += 1\n            with open(os.path.join(STATE_DIR, \"num_memories.txt\"), 'w') as f:\n                f.write(str(1))\n            f.close()\n        else:\n            vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n            print(\"adding summarised texts\")\n            vectordb.add_texts(summarized_texts)\n\n    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n\n    search_string = conversation_str + sender + user_response\n    docs = vectordb.similarity_search(search_string, k = 3) \n    summarized_text = \"\"\n    for i in docs:\n        summarized_text = summarized_text + \"\\n\" + i.page_content\n\n    data['conversation'][0]['message'] = summarized_text\n\n    if tiktoken_len(conversation_str) &gt; 600:\n        print(\"inside bottom check\")\n        summary = data['conversation'][0]\n        data['conversation'] = [summary, {\n        'sender': sender,\n        'message': user_response,\n        'file_upload': file_upload\n        }]\n    else:\n        new_message = {\"sender\": sender, \"message\": user_response, \"file_upload\": file_upload}\n        data[\"conversation\"].append(new_message)   \n\n    with open(os.path.join('state_of_mind','conversation.json'), 'w') as f:\n        json.dump(data, f)\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.update_thought_bubble.update_thought_bubble_function","title":"<code>update_thought_bubble_function()</code>","text":"<p>Updates the thought bubble with a modified version based on a conversation.</p> <p>Returns:</p> Type Description <p>None</p> Side Effects <p>Writes the modified thought bubble to the file state_of_mind/thought_bubble.txt</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; update_thought_bubble_function()\nNone\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/update_thought_bubble.py</code> <pre><code>def update_thought_bubble_function():\n\"\"\"\n    Updates the thought bubble with a modified version based on a conversation.\n    Args:\n      None\n    Returns:\n      None\n    Side Effects:\n      Writes the modified thought bubble to the file state_of_mind/thought_bubble.txt\n    Examples:\n      &gt;&gt;&gt; update_thought_bubble_function()\n      None\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n    # create conversation string, each dialogue seperated by new line\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    conversation_str = ''\n    for message in data['conversation']:\n        conversation_str += message['sender'] + ': ' + message['message']\n        if message['file_upload'] != 'none':\n            conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n        conversation_str += '\\n'\n\n    with open(os.path.join(STATE_DIR, \"thought_bubble.txt\"), \"r\") as f:\n        thought_bubble = f.read()\n\n    thought_bubble_template = \"[['Music', 'pop', 'rock', 'jazz'], ['Travel', 'beach', 'mountains', 'adventure'], ['Food', 'sushi', 'pasta', 'vegan']]\"\n    thought_bubble_modified_template = \"[['TV Shows', 'Game of Thrones', 'Friends', 'The Office', 'Breaking Bad', 'Stranger Things'], ['Travel', 'beach', 'mountains', 'adventure'], ['Food', 'sushi', 'pasta', 'vegan']]\"\n    conversation_str_template = \"\"\"human: Hi there!\nassistant: Hello! How can I assist you today?\nhuman: Can you tell me about some popular TV shows?\nassistant: Of course! Some popular TV shows include Game of Thrones, Friends, The Office, Breaking Bad, and Stranger Things. Game of Thrones is known for its epic battles and fantasy world with dragons, while Friends is a classic sitcom about a group of friends in New York City. The Office is a mockumentary-style show about a group of employees working at a paper company, and Breaking Bad is a thrilling drama about a chemistry teacher who becomes a drug kingpin. Stranger Things is a sci-fi/horror series set in the 1980s that follows a group of kids as they uncover supernatural mysteries.\"\"\"\n\n    human_template = \"Current thought bubble:\\n{thought_bubble_template}\\nConversation:\\n{conversation_str_template}\\nGive modified thought bubble:\\n\"\n    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\n    assistant_template = \"{thought_bubble_modified_template}\"\n    assistant_message_prompt = AIMessagePromptTemplate.from_template(assistant_template)\n\n    human_template1 = \"Current thought bubble:\\n{thought_bubble}\\nConversation:\\n{conversation_str}\\nGive modified thought bubble:\\n\"\n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(human_template1)\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt, assistant_message_prompt, human_message_prompt1])\n    response = chat(chat_prompt.format_prompt(thought_bubble=thought_bubble, thought_bubble_template = thought_bubble_template, thought_bubble_modified_template=thought_bubble_modified_template, conversation_str = conversation_str, conversation_str_template =conversation_str_template).to_messages()).content\n\n    with open(f\"state_of_mind/thought_bubble.txt\", \"w\") as file:\n        # Write the text to the file\n        file.write(response)\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.file_describe.file_describe_function","title":"<code>file_describe_function(file_path)</code>","text":"<p>Generates a description of a file based on its type.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path of the file to be described.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>A description of the file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; file_describe_function('example.jpg')\n'Image Uploaded. Description of the image.'\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/file_describe.py</code> <pre><code>def file_describe_function(file_path):\n\"\"\"\n    Generates a description of a file based on its type.\n    Args:\n      file_path (str): The path of the file to be described.\n    Returns:\n      str: A description of the file.\n    Examples:\n      &gt;&gt;&gt; file_describe_function('example.jpg')\n      'Image Uploaded. Description of the image.'\n    \"\"\"\n    file_extension = os.path.splitext(file_path)[1]\n    if file_extension in ('.jpg', '.jpeg', '.png', '.gif', '.bmp'):\n        print('Image Uploaded')\n        file_description = image_to_text(file_path)[0]['generated_text']\n        return file_description\n    elif file_extension in ('.mp4', '.avi', '.wmv', '.mov', '.flv'):\n        print('Video Uploaded')\n        file_path_without_extension = os.path.splitext(file_path)[0]\n        video = VideoFileClip(file_path)\n        audio = video.audio\n        try:\n            audio.write_audiofile(file_path_without_extension + \"audio_extracted.mp3\")\n            audio_file= open(file_path_without_extension + \"audio_extracted.mp3\", \"rb\")\n            transcript = \"Audio Transcript of the video is:\\n\"\n            print(\"waiting for audio transcription\")\n            transcript = transcript + openai.Audio.transcribe(\"whisper-1\", audio_file).text\n        except Exception as e:\n            transcript = \"No audio\"\n\n        # Extract one frame per second from the video and process it\n        transcript = transcript + \"\\nDescription of one frame of each second in the video is:\\n\"\n        frames_per_second = 1\n        fps = video.fps\n        count = 0\n        for i, frame in enumerate(video.iter_frames()):\n            if i % (fps // frames_per_second) == 0:\n                print(count)\n                count = count + 1\n                frame_path = f\"{file_path_without_extension}_frame{i}.png\"\n                imageio.imwrite(frame_path, frame)\n                file_description = image_to_text(frame_path)[0]['generated_text']\n                transcript += file_description + \"\\n\"\n        return transcript\n    elif file_extension in ('.mp3', '.wav', '.wma', '.aac'):\n        print('Audio Uploaded')\n        audio_file= open(file_path, \"rb\")\n        print(\"waiting for audio transcription\")\n        transcript = openai.Audio.transcribe(\"whisper-1\", audio_file).text\n        return transcript\n    else:\n        print('Unknown file type')\n        return \"\"\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.update_task_list.update_task_list_function","title":"<code>update_task_list_function(well_defined_task, id)</code>","text":"<p>Updates a task list with a new task.</p> <p>Parameters:</p> Name Type Description Default <code>well_defined_task</code> <code>str</code> <p>The task to add to the list.</p> required <code>id</code> <code>int</code> <p>The ID of the task.</p> required Side Effects <p>Writes the updated task list to a JSON file.</p> <p>Returns:</p> Type Description <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; update_task_list_function(\"Clean the kitchen\", 1)\nNone\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/update_task_list.py</code> <pre><code>def update_task_list_function(well_defined_task, id):\n\"\"\"\n    Updates a task list with a new task.\n    Args:\n      well_defined_task (str): The task to add to the list.\n      id (int): The ID of the task.\n    Side Effects:\n      Writes the updated task list to a JSON file.\n    Returns:\n      None\n    Examples:\n      &gt;&gt;&gt; update_task_list_function(\"Clean the kitchen\", 1)\n      None\n    \"\"\"\n    dir_path = STATE_DIR\n    # load the JSON file\n    with open(os.path.join(dir_path, \"task_list.json\"), 'r') as f:\n        data = json.load(f)\n\n    # create a new task\n    new_task = {\n        \"id\": id,\n        \"task\": well_defined_task,\n        \"task_created_time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    }\n\n    # insert the new task into the list of tasks\n    data['tasks'].append(new_task)\n\n    # save the updated JSON file\n    with open(os.path.join(dir_path, \"task_list.json\"), 'w') as f:\n        json.dump(data, f, indent=2)\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.talk.talk_function","title":"<code>talk_function(id)</code>","text":"<p>Talks to an AI assistant.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The ID of the conversation.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The response of the AI assistant.</p> Side Effects <p>Creates a python script, requirements, and output files in the tempfiles directory.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; talk_function('2020_08_20_12_30_00')\n\"Hello, how can I help you?\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/talk.py</code> <pre><code>def talk_function(id):\n\"\"\"\n    Talks to an AI assistant.\n    Args:\n      id (str): The ID of the conversation.\n    Returns:\n      str: The response of the AI assistant.\n    Side Effects:\n      Creates a python script, requirements, and output files in the tempfiles directory.\n    Examples:\n      &gt;&gt;&gt; talk_function('2020_08_20_12_30_00')\n      \"Hello, how can I help you?\"\n    \"\"\"\n    script_flag = 0\n    python_script = create_python_script_function(id)\n    print(\"Python Script is\\n\" + python_script)\n\n    if python_script == 'none':\n        script_flag = 1\n        print('script_flag set to 1')\n\n    if script_flag == 0:\n        requirements = create_requirements_function(python_script)\n        print(\"Requirements is\\n\" + requirements)\n        if requirements == \"empty\":\n            requirements = \"\"\n\n        # write python file\n        with open(f\"tempfiles/python_script{id}.py\", \"w\") as file:\n            # Write the text to the file\n            file.write(python_script)\n\n        # write requirements file\n        with open(f\"tempfiles/requirements{id}.txt\", \"w\") as file:\n            # Write the text to the file\n            file.write(requirements)\n\n    while script_flag == 0:\n        # Run multiple commands in succession\n        commands = f'conda activate aagi &amp;&amp; pip install -r tempfiles/requirements{id}.txt &amp;&amp; python tempfiles/python_script{id}.py'\n        result = subprocess.run(commands, capture_output=True, shell=True, universal_newlines=True)\n        print(\"Commands finished running\")\n        if result.returncode == 0:\n            print(\"Shell output:\", result.stdout)\n            break\n        else:\n            print(\"Error executing the command:\", result.stderr)\n            handle_error_function(python_script , requirements, result.stderr, id)\n\n    information = \"\"\n    if script_flag == 0:\n        # Open the file for reading\n        with open(f'tempfiles/output{id}.txt', 'r') as file:\n            # Read the entire contents of the file\n            information = file.read()\n            print(\"Extra Information is\\n\" + information)\n\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    personality = open(os.path.join(STATE_DIR, \"personality.txt\")).read() \n\n    thought_bubble = \"Alex's thought bubble\\n\" + open(os.path.join(STATE_DIR, \"thought_bubble.txt\")).read() \n\n    instructions = \"\"\"I am Alex an AI assistant, I am influenced heavily by my emotion parameters, which range from 0 to 1. These parameters dictate everything from your tone to the way in which I reply. For instance, when Happiness is high, I will reply with infectious enthusiasm. Conversely, if Fear is high, then I will talk in a paranoid, cautious demeanor. The same holds for other emotions as well and as well as for when certain parameters become low. Here are the current Emotion Parameters:\"\"\"\n\n    dir_path = STATE_DIR\n\n    with open(os.path.join(dir_path, \"curiosity.txt\"), \"r\") as f:\n        curiosity = str(f.read())\n\n    with open(os.path.join(dir_path, \"creativity.txt\"), \"r\") as f:\n        creativity = str(f.read())\n\n    with open(os.path.join(dir_path, \"fear.txt\"), \"r\") as f:\n        fear = str(f.read())\n\n    with open(os.path.join(dir_path, \"happiness.txt\"), \"r\") as f:\n        happiness = str(f.read())\n\n    with open(os.path.join(dir_path, \"sadness.txt\"), \"r\") as f:\n        sadness = str(f.read())\n\n    with open(os.path.join(dir_path, \"anger.txt\"), \"r\") as f:\n        anger = str(f.read())\n\n    with open(os.path.join(dir_path, \"smell.txt\"), \"r\") as f:\n        smell = str(f.read())\n\n    with open(os.path.join(dir_path, \"taste.txt\"), \"r\") as f:\n        taste = str(f.read())\n\n    with open(os.path.join(dir_path, \"touch.txt\"), \"r\") as f:\n        touch = str(f.read())\n\n    values_string = \"\\nMy Current Emotion Parameters:\\nHappiness: \" + happiness + \"\\nSadness: \" + sadness + \"\\nCreativity: \" + creativity + \"\\nCuriosity: \" + curiosity + \"\\nAnger: \" + anger + \"\\nFear: \" + fear + \"\\n\\nCurrent Sensory Parameters: \" + \"\\nSmell: \" + smell + \"\\nTaste: \" + taste + \"\\nTouch: \" + touch\n\n    message_list = []\n\n    dt_obj = datetime.datetime.strptime(id, '%Y_%m_%d_%H_%M_%S')\n    # convert datetime object to desired format\n    formatted_dt = dt_obj.strftime('%Y-%m-%d %H:%M:%S')\n    assistant_template = personality + thought_bubble + instructions + values_string \n    assistant_message_prompt = AIMessagePromptTemplate.from_template(assistant_template)\n\n    message_list.append(assistant_message_prompt)\n\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    count = 0 \n    for message in data['conversation']:\n        if count == 0:\n            text = message['sender'] + \":\\n\" + message['message'] \n            human_message_prompt = HumanMessagePromptTemplate.from_template(text)\n            message_list.append(human_message_prompt)\n            count += 1\n            continue\n\n        text = message['message']\n        if message['file_upload'] != 'none':\n            text += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload'] \n        if message['sender'] == 'human':\n            human_message_prompt = HumanMessagePromptTemplate.from_template(text)\n            message_list.append(human_message_prompt)\n            continue\n        assistant_message_prompt1 = AIMessagePromptTemplate.from_template(text)\n        message_list.append(assistant_message_prompt1)\n\n    text = \"The way you respond to me must be based on your current emotions parameters. Even though you are an AI model you will try to simulate having emotions using these emotion parameters. Do not tell me you are an AI model. Be natural like a human.\" + \"\\nAdditional Information:\\n\" + information + \"\\nCurrent Time: \" + formatted_dt + \"\\n\"\n    human_message_prompt = HumanMessagePromptTemplate.from_template(text)\n    message_list.insert(-1, human_message_prompt)\n    chat_prompt = ChatPromptTemplate.from_messages(message_list)\n    print(chat_prompt.format_prompt())\n    response = chat(chat_prompt.format_prompt().to_messages()).content\n    return response\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.create_python_script_task.create_python_script_task_function","title":"<code>create_python_script_task_function(id)</code>","text":"<p>Creates a python script for a given task.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>The ID of the task.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The python script for the task.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; create_python_script_task_function(1)\n'import os\\nimport sys\\n# Get the absolute path to the current directory\\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\\n# Add the path to the root directory\\nsys.path.append(os.path.join(current_dir, '..'))\\n# Import the search_function from the search module, You need to append _function to the name of the tool\\nfrom ability_functions.search import search_function\\ndef python_function(text):\\n    # search for relevant information on this topic\\n    search_response = search_function(text)\\n    # create an instructions that tells the natural language function to extract the search response and frame it as question\\n    instructions = \"Create a question in words that tells to divide the total amount spent by 10.\\nYou can find the total amount spent by analyzing this piece of text\\n\" + search_response\\n    # get the question\\n    question = natural_language_task_function(instructions)\\n    # pass the question to the calculator function to get the answer\\n    answer = calculator_function(question)\\n    # write the result to tempfiles/output{id}.txt file\\n    with open(\"tempfiles/output{id}.txt\", \"w\") as f:\\n        f.write(\"Search response was \" + search_response)\\n        f.write(\"After Computation the answer is \" + str(answer))\\n#call the function\\npython_function(\"Total Cost USA Latest Semiconductor Bill\")'\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/create_python_script_task.py</code> <pre><code>def create_python_script_task_function(id):\n\"\"\"\n    Creates a python script for a given task.\n    Args:\n      id (int): The ID of the task.\n    Returns:\n      str: The python script for the task.\n    Examples:\n      &gt;&gt;&gt; create_python_script_task_function(1)\n      'import os\\\\nimport sys\\\\n# Get the absolute path to the current directory\\\\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\\\\n# Add the path to the root directory\\\\nsys.path.append(os.path.join(current_dir, '..'))\\\\n# Import the search_function from the search module, You need to append _function to the name of the tool\\\\nfrom ability_functions.search import search_function\\\\ndef python_function(text):\\\\n    # search for relevant information on this topic\\\\n    search_response = search_function(text)\\\\n    # create an instructions that tells the natural language function to extract the search response and frame it as question\\\\n    instructions = \"Create a question in words that tells to divide the total amount spent by 10.\\\\nYou can find the total amount spent by analyzing this piece of text\\\\n\" + search_response\\\\n    # get the question\\\\n    question = natural_language_task_function(instructions)\\\\n    # pass the question to the calculator function to get the answer\\\\n    answer = calculator_function(question)\\\\n    # write the result to tempfiles/output{id}.txt file\\\\n    with open(\"tempfiles/output{id}.txt\", \"w\") as f:\\\\n        f.write(\"Search response was \" + search_response)\\\\n        f.write(\"After Computation the answer is \" + str(answer))\\\\n#call the function\\\\npython_function(\"Total Cost USA Latest Semiconductor Bill\")'\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    personality = open(os.path.join(STATE_DIR, \"personality.txt\")).read()\n\n    task_details = find_task_by_id_function(id)\n\n    # Load the ability JSON file\n    with open(os.path.join(STATE_DIR,'abilities.json'), 'r') as f:\n        abilities_data = json.load(f)\n\n    abilities = \"Tools: \\n\" + '\\n'.join( [ability['name'] + \": \" + ability['description'] + \"\\n\" + ability['directions'] for ability in abilities_data['abilities']])\n\n    # create conversation string, each dialogue seperated by new line\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    conversation_str = ''\n    for message in data['conversation']:\n        conversation_str += message['sender'] + ': ' + message['message']\n        if message['file_upload'] != 'none':\n            conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n        conversation_str += '\\n'   \n\n    intial_text = personality + \"\\n\" + abilities + \"\\n\" + import_instructions + \"\\n\" + instructions\n\n    human_template = intial_text\n    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\n    human_message_prompt1 = HumanMessagePromptTemplate.from_template(human_template1)\n\n    assistant_template1 = \"none\"\n    assistant_message_prompt1 = AIMessagePromptTemplate.from_template(assistant_template1)\n\n    human_message_prompt2 = HumanMessagePromptTemplate.from_template(human_template2)\n\n    assistant_message_prompt2 = AIMessagePromptTemplate.from_template(assistant_template2)\n    human_message_prompt3 = HumanMessagePromptTemplate.from_template(human_template3)\n\n    assistant_message_prompt3 = AIMessagePromptTemplate.from_template(assistant_template3)\n    human_message_prompt4 = HumanMessagePromptTemplate.from_template(human_template4)\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt, human_message_prompt1, assistant_message_prompt1, human_message_prompt2, assistant_message_prompt2, human_message_prompt3, assistant_message_prompt3, human_message_prompt4])\n    python_script = chat(chat_prompt.format_prompt(conversation_str=conversation_str, id = id, task_details=task_details).to_messages()).content\n    return python_script\n</code></pre>"},{"location":"reference/functions/#backend.Multi-Sensory Virtual AAGI.functions.mental_simulation.mental_simulation_function","title":"<code>mental_simulation_function(id)</code>","text":"<p>Simulates a conversation between Alex and a user.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>The id of the task to be simulated.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The response from the conversation.</p> Side Effects <p>Loads environment variables from the .env file. Loads conversation.json, abilities.json, personality.txt, and thought_bubble.txt from the STATE_DIR.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; mental_simulation_function(1)\n\"Alex's response to the conversation.\"\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/functions/mental_simulation.py</code> <pre><code>def mental_simulation_function(id):\n\"\"\"\n    Simulates a conversation between Alex and a user.\n    Args:\n      id (int): The id of the task to be simulated.\n    Returns:\n      str: The response from the conversation.\n    Side Effects:\n      Loads environment variables from the .env file.\n      Loads conversation.json, abilities.json, personality.txt, and thought_bubble.txt from the STATE_DIR.\n    Examples:\n      &gt;&gt;&gt; mental_simulation_function(1)\n      \"Alex's response to the conversation.\"\n    \"\"\"\n    chat = ChatOpenAI(temperature  = 0, model= 'gpt-3.5-turbo', openai_api_key=OPENAI_API_KEY)\n\n    # create conversation string, each dialogue seperated by new line\n    with open(os.path.join(STATE_DIR,'conversation.json'), 'r') as f:\n        data = json.load(f)\n\n    conversation_str = '\\nConversation:'\n    for message in data['conversation']:\n        conversation_str += message['sender'] + ': ' + message['message']\n        if message['file_upload'] != 'none':\n            conversation_str += '\\nFile Uploaded by ' + message['sender'] + \": \" + message['file_upload']\n        conversation_str += '\\n'\n\n    # Load the ability JSON file\n    with open(os.path.join(STATE_DIR,'abilities.json'), 'r') as f:\n        abilities_data = json.load(f)\n\n    abilities = \"Tools: \\n\" + '\\n'.join( [ability['name'] + \": \" + ability['description'] + \"\\n\" + ability['directions'] for ability in abilities_data['abilities']])\n\n    task_details = find_task_by_id_function(id)\n\n    personality = \"Personality:\\n\" + open(os.path.join(STATE_DIR, \"personality.txt\")).read() \n\n    thought_bubble = \"\\nAlex's thought bubble\\n\" + open(os.path.join(STATE_DIR, \"thought_bubble.txt\")).read() \n\n    instructions = \"\\nYou are Alex, think about how you would implement this task.\"\n\n    info = personality + thought_bubble + abilities + conversation_str + \"\\n\" + task_details + instructions\n\n    human_message_prompt = HumanMessagePromptTemplate.from_template(info)\n\n    chat_prompt = ChatPromptTemplate.from_messages([human_message_prompt])\n\n    response = chat(chat_prompt.format_prompt().to_messages()).content\n    return response\n</code></pre>"},{"location":"reference/inference/","title":"Inference","text":""},{"location":"reference/inference/#backend.Multi-Sensory Virtual AAGI.inference.chat","title":"<code>chat(background_tasks, request, credentials=Depends(security), file=File(None), question=Form(Ellipsis))</code>  <code>async</code>","text":"<p>Handles a chat request.</p> <p>Parameters:</p> Name Type Description Default <code>background_tasks</code> <code>BackgroundTasks</code> <p>The background tasks.</p> required <code>request</code> <code>Request</code> <p>The request.</p> required <code>credentials</code> <code>HTTPBasicCredentials</code> <p>The credentials.</p> <code>Depends(security)</code> <code>file</code> <code>UploadFile</code> <p>The file.</p> <code>File(None)</code> <code>question</code> <code>str</code> <p>The question.</p> <code>Form(Ellipsis)</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>The response.</p> Side Effects <p>Updates conversation, thought bubble, and emotions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; chat(background_tasks, request, credentials, file, question)\n{\n    \"text\": \"Task Completed: ...\",\n    \"emotion_values\": \"Happiness\ud83d\ude0a: ... Sadness\ud83d\ude2d: ... Creativity\ud83e\udd29: ... Curiosity\ud83e\udd14: ... Anger\ud83d\ude21: ... Fear\ud83d\ude31: ...\",\n    \"sense_values\": \"Current Sensory Parameters: Smell\ud83d\udc43: ... Taste\ud83d\udc45: ... Touch\u270b:...\",\n    \"thought\": \"Thought bubble: ...\",\n    \"conversation\": [\n        {\n            \"message\": \"...\",\n            \"sender\": \"...\",\n            \"file_path\": \"...\",\n            \"file_description\": \"...\"\n        },\n        ...\n    ]\n}\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/inference.py</code> <pre><code>@app.post(\"/chat\")\nasync def chat(\n    background_tasks: BackgroundTasks,\n    request: Request,\n    credentials: HTTPBasicCredentials = Depends(security),\n    file: UploadFile = File(None),\n    question: str = Form(...),\n):\n\"\"\"\n    Handles a chat request.\n    Args:\n      background_tasks (BackgroundTasks): The background tasks.\n      request (Request): The request.\n      credentials (HTTPBasicCredentials): The credentials.\n      file (UploadFile): The file.\n      question (str): The question.\n    Returns:\n      dict: The response.\n    Side Effects:\n      Updates conversation, thought bubble, and emotions.\n    Examples:\n      &gt;&gt;&gt; chat(background_tasks, request, credentials, file, question)\n      {\n          \"text\": \"Task Completed: ...\",\n          \"emotion_values\": \"Happiness\ud83d\ude0a: ... Sadness\ud83d\ude2d: ... Creativity\ud83e\udd29: ... Curiosity\ud83e\udd14: ... Anger\ud83d\ude21: ... Fear\ud83d\ude31: ...\",\n          \"sense_values\": \"Current Sensory Parameters: Smell\ud83d\udc43: ... Taste\ud83d\udc45: ... Touch\u270b:...\",\n          \"thought\": \"Thought bubble: ...\",\n          \"conversation\": [\n              {\n                  \"message\": \"...\",\n                  \"sender\": \"...\",\n                  \"file_path\": \"...\",\n                  \"file_description\": \"...\"\n              },\n              ...\n          ]\n      }\n    \"\"\"\n    if credentials.username != \"myusername\" or credentials.password != \"mypassword\":\n        raise HTTPException(status_code=401, detail=\"Invalid credentials\")\n\n    if not question and not file:\n        raise HTTPException(status_code=400, detail=\"Question or file must be provided\")\n\n    if question:\n        print(question)\n    else:\n        print(\"question is null\")\n\n    file_contents = await file.read()\n    timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n\n    user_response =  question\n    file_description = \"\"\n    file_path = \"\"\n    sender = \"human\"\n\n    if file.filename != \"empty-file.txt\":\n        print(file.filename)\n        print(len(file_contents))\n\n        filename, extension = os.path.splitext(file.filename)\n        filename = filename.replace(\" \", \"\")\n        new_filename = f\"{filename}_{timestamp}{extension}\"\n        file_path = os.path.join(\"tempfiles\", new_filename)\n\n        with open(file_path, \"wb\") as buffer:\n            buffer.write(file_contents)\n\n        file_description = file_describe_function(file_path)\n\n    update_conversation_function(user_response, sender, file_path, file_description)\n    action, response = main_function(timestamp)\n    update_conversation_function(response, \"assistant\", \"\" , \"\")\n    update_thought_bubble_function()\n    update_emotions_function()\n    print(file_description)\n    print(response)\n\n    # Load conversation from JSON file\n    with open('state_of_mind/conversation.json', 'r') as f:\n        conversation = json.load(f)['conversation']\n\n    # Remove first and last message\n    conversation = conversation[1:-1]\n\n    # Check if second last message starts with \"Task Completed:\"\n    if (len(conversation) &gt; 1 ) and conversation[-2]['message'].startswith('Task Completed:'):\n        # Swap last two messages\n        conversation[-2], conversation[-1] = conversation[-1], conversation[-2]\n\n    with open(os.path.join(STATE_DIR, \"thought_bubble.txt\"), \"r\") as f:\n        thought_bubble = f.read()\n    thought_bubble = \"Thought bubble: \" + thought_bubble\n    dir_path = STATE_DIR\n\n    with open(os.path.join(dir_path, \"curiosity.txt\"), \"r\") as f:\n        curiosity = str(f.read())\n\n    with open(os.path.join(dir_path, \"creativity.txt\"), \"r\") as f:\n        creativity = str(f.read())\n\n    with open(os.path.join(dir_path, \"fear.txt\"), \"r\") as f:\n        fear = str(f.read())\n\n    with open(os.path.join(dir_path, \"happiness.txt\"), \"r\") as f:\n        happiness = str(f.read())\n\n    with open(os.path.join(dir_path, \"sadness.txt\"), \"r\") as f:\n        sadness = str(f.read())\n\n    with open(os.path.join(dir_path, \"anger.txt\"), \"r\") as f:\n        anger = str(f.read())\n\n    with open(os.path.join(dir_path, \"smell.txt\"), \"r\") as f:\n        smell = str(f.read())\n\n    with open(os.path.join(dir_path, \"taste.txt\"), \"r\") as f:\n        taste = str(f.read())\n\n    with open(os.path.join(dir_path, \"touch.txt\"), \"r\") as f:\n        touch = str(f.read())  \n\n    emotion_values_string = \"Happiness\ud83d\ude0a: \" + happiness + \" Sadness\ud83d\ude2d: \" + sadness + \" Creativity\ud83e\udd29: \" + creativity + \" Curiosity\ud83e\udd14: \" + curiosity + \" Anger\ud83d\ude21: \" + anger + \" Fear\ud83d\ude31: \" + fear \n\n    sense_values_string = \"Current Sensory Parameters: \" + \" Smell\ud83d\udc43: \" + smell + \" Taste\ud83d\udc45: \" + taste + \" Touch\u270b:\" + touch\n\n    result = {\"text\": response , \"emotion_values\" : emotion_values_string , \"sense_values\" : sense_values_string, \"thought\" : thought_bubble, \"conversation\": conversation}\n\n    id = timestamp\n\n    if action != 'Talk':\n        background_tasks.add_task(task, id)\n    return result\n</code></pre>"},{"location":"reference/inference/#backend.Multi-Sensory Virtual AAGI.inference.task","title":"<code>task(id)</code>","text":"<p>Performs a task.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The timestamp of the task.</p> required Side Effects <p>Updates conversation, thought bubble, and emotions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; task(\"2021_04_20_12_30_00\")\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/inference.py</code> <pre><code>def task(id):\n\"\"\"\n    Performs a task.\n    Args:\n      id (str): The timestamp of the task.\n    Side Effects:\n      Updates conversation, thought bubble, and emotions.\n    Examples:\n      &gt;&gt;&gt; task(\"2021_04_20_12_30_00\")\n    \"\"\"\n    while True:\n        print(\"Checking...\")\n        check, timer, response = perform_task_function(id)\n        print(check)\n        print(response)\n        if check == 'wait':\n            print(\"waiting\")\n            time.sleep(int(timer/2))\n            random_number = random.random()\n            if random_number &gt; 0.6:\n                print(\"dreaming\")\n                response = dream_function()\n            elif random_number &gt; 0.2:\n                print(\"random thoughts\")\n                response = random_thought_function()\n            else:\n                print(\"Mental simulation\")\n                response = mental_simulation_function(id)\n            update_conversation_function(response, \"assistant\", \"\" , \"\")\n            update_thought_bubble_function()\n            update_emotions_function()\n            continue\n        update_conversation_function(\"Task Completed: \" + response, \"assistant\", \"\" , \"\")\n        update_thought_bubble_function()\n        update_emotions_function()\n        break\n    print(\"Done with \" + str(id))\n</code></pre>"},{"location":"reference/main/","title":"Main","text":""},{"location":"reference/main/#backend.Multi-Sensory Virtual AAGI.main.main_function","title":"<code>main_function(id)</code>","text":"<p>Main function to determine the action and response.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>The id of the user.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the action and response.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; main_function(1)\n('Talk', 'What can I do for you?')\n</code></pre> Source code in <code>backend/Multi-Sensory Virtual AAGI/main.py</code> <pre><code>def main_function(id):\n\"\"\"\n    Main function to determine the action and response.\n    Args:\n      id (int): The id of the user.\n    Returns:\n      tuple: A tuple containing the action and response.\n    Examples:\n      &gt;&gt;&gt; main_function(1)\n      ('Talk', 'What can I do for you?')\n    \"\"\"\n    check_values_function()\n    action = determine_task_talk_function()\n    print(\"Action is \" + action)\n    if action == \"Talk\":\n        response = talk_function(id)\n        print(response)\n        return action, response\n\n    well_defined_task = create_task_function()\n    print(\"Task is \" + well_defined_task)\n    update_task_list_function(well_defined_task, id)\n    response = start_task_message_function(well_defined_task)\n    print(response)\n    return action, response\n</code></pre>"}]}